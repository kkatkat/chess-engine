{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from data_loading import load_games, load_data, board_to_tensor\n",
    "from moves_encoder import MovesEncoder\n",
    "from typing import List\n",
    "from chess.pgn import Game\n",
    "from chess import Board, Move\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from Model import Model\n",
    "\n",
    "from tqdm import tqdm\n",
    "from EarlyStopping import EarlyStopping\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = load_games('lichess_elite_2023-05.pgn')\n",
    "\n",
    "encoder = MovesEncoder()\n",
    "data_generator = load_data(games, encoder, limit_moves=8_000_000)\n",
    "\n",
    "X, y = [], []\n",
    "for X_data, y_data in data_generator:\n",
    "    X.append(X_data)\n",
    "    y.append(y_data)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.125, random_state=42)  # 0.125 * 0.8 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for pytorch\n",
    "X_train = torch.tensor(X_train, dtype=torch.bool)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.bool)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.bool)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_dataset, 'train_dataset.pt')\n",
    "torch.save(test_dataset, 'test_dataset.pt')\n",
    "torch.save(val_dataset, 'val_dataset.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the processed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset: TensorDataset = torch.load('train_dataset.pt')\n",
    "test_dataset: TensorDataset = torch.load('test_dataset.pt')\n",
    "val_dataset: TensorDataset = torch.load('val_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5600000, 1600000, 800000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "validation_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of moves: 4608\n"
     ]
    }
   ],
   "source": [
    "encoder = MovesEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(num_actions=encoder.num_actions).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: torch.nn.Module, criterion: torch.nn.CrossEntropyLoss, optimizer: torch.optim.Optimizer, train_loader: DataLoader, validation_loader: DataLoader, epochs = 150, save_every = 10):\n",
    "    model.to(device)\n",
    "    early_stopping = EarlyStopping(patience=5, min_delta=0.001)\n",
    "\n",
    "    history = {\n",
    "        'epoch': [],\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "    }\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        # training\n",
    "        running_train_loss = 0.0\n",
    "        for data in tqdm(train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device).float(), labels.to(device).long()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item()\n",
    "        \n",
    "        epoch_train_loss = running_train_loss / len(train_loader)\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in validation_loader:\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device).float(), labels.to(device).long()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item()\n",
    "            \n",
    "        epoch_val_loss = running_val_loss / len(validation_loader)\n",
    "\n",
    "        history['epoch'].append(epoch + 1)\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs} - Train loss: {epoch_train_loss:.4f} - Validation loss: {epoch_val_loss:.4f}')\n",
    "\n",
    "        # saving the model\n",
    "        if (epoch + 1) % save_every == 0:\n",
    "            torch.save(model.state_dict(), f'model_epoch_{epoch + 1}.pth')\n",
    "\n",
    "        # early stopping\n",
    "        if early_stopping.early_stop(epoch_val_loss):\n",
    "            print(f'Early stopping on epoch {epoch+1}')\n",
    "            torch.save(model.state_dict(), f'model_final_epoch{epoch + 1}.pth')\n",
    "            break\n",
    "    \n",
    "    history_df = pd.DataFrame(history)\n",
    "    return history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87500/87500 [08:19<00:00, 175.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train loss: 2.2804 - Validation loss: 2.2549\n",
      "    Validation loss decreased (inf --> 2.2549). Resetting counter to 0. New threshold is 2.2559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87500/87500 [08:04<00:00, 180.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Train loss: 2.1727 - Validation loss: 2.1957\n",
      "    Validation loss decreased (2.2549 --> 2.1957). Resetting counter to 0. New threshold is 2.1967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87500/87500 [08:05<00:00, 180.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Train loss: 2.1187 - Validation loss: 2.1651\n",
      "    Validation loss decreased (2.1957 --> 2.1651). Resetting counter to 0. New threshold is 2.1661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87500/87500 [08:08<00:00, 178.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Train loss: 2.0865 - Validation loss: 2.1615\n",
      "    Validation loss decreased (2.1651 --> 2.1615). Resetting counter to 0. New threshold is 2.1625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87500/87500 [08:31<00:00, 171.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Train loss: 2.0662 - Validation loss: 2.1519\n",
      "    Validation loss decreased (2.1615 --> 2.1519). Resetting counter to 0. New threshold is 2.1529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87500/87500 [08:07<00:00, 179.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Train loss: 2.0484 - Validation loss: 2.1470\n",
      "    Validation loss decreased (2.1519 --> 2.1470). Resetting counter to 0. New threshold is 2.1480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87500/87500 [08:01<00:00, 181.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Train loss: 2.0481 - Validation loss: 2.1351\n",
      "    Validation loss decreased (2.1470 --> 2.1351). Resetting counter to 0. New threshold is 2.1361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87500/87500 [07:58<00:00, 182.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Train loss: 2.0268 - Validation loss: 2.1474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87500/87500 [08:03<00:00, 180.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Train loss: 2.0205 - Validation loss: 2.1568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87500/87500 [08:07<00:00, 179.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Train loss: 2.0195 - Validation loss: 2.1373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87500/87500 [08:00<00:00, 182.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Train loss: 2.0177 - Validation loss: 2.1376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87500/87500 [07:52<00:00, 185.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Train loss: 2.0195 - Validation loss: 2.1417\n",
      "Early stopping on epoch 12\n"
     ]
    }
   ],
   "source": [
    "history = train_model(model, criterion, optimizer, train_loader, validation_loader, epochs=20, save_every=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of moves: 4608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(19, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc1): Linear(in_features=8192, out_features=512, bias=True)\n",
       "  (fc_relu1): ReLU()\n",
       "  (fc2): Linear(in_features=512, out_features=4608, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "encoder = MovesEncoder()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Model(num_actions=encoder.num_actions).to(device)\n",
    "model.load_state_dict(torch.load('model_epoch_12.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.1437154840373993, 0.391163125)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# test\n",
    "model.eval()\n",
    "running_test_loss = 0.0\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device).float(), labels.to(device).long()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_test_loss += loss.item()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "test_loss = running_test_loss / len(test_loader)\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "test_loss, accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
